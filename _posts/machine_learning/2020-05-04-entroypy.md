---
title: Information Theory
published: true
tags:
  - ML
  - Information Theory
---

The _basic intuition_ of information theory is that knowing a unlikely event is more informative than knowing a likely event has occurred.

<!--more-->

For example, a message saying "the sun will rise tomorrow" is so uninformative than a message saying "the sun won't rise tomorrow".

Now, we have to think a way to quantify information in a way that formalize the _intuition_ so we could measure and compare between messages.

Here are some properties we should consider of the chosen measurement:

- Likely events should have low information scores. And events that are 100% going to happen should have no information score (0)
- Less likely events should have high information scores.
- Independent events should have additive information. For example, finding out that a tossed coin has come up as heads twice should convey twice as much information as finding out that a tossed coin has come up as heads once.

In order to satisfy all three of these properties, we define the [self-information] of an event $$ \text{x} = $$ to be:

$$
\begin{align}
I(x) = -\log P(x)
\end{align}
$$

<div class="text-center border">
  <iframe src="{{ site.baseurl }}/assets/demo/entropy.html" width="100%" height="750px;" style="border:none;"></iframe>
</div>

[self-information]: https://en.wikipedia.org/wiki/Information_content
