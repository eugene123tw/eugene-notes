---
title: Mask RCNN
tags:
  - Computer Vision
---

<!--more-->

Mask R-CNN 為 Faster R-CNN 的延伸, 原架構有 2 個分支 1. Classification branch 與 2. Bounding box branch , 而 Mask R-CNN 的方法則是多加了另一個分支 3. Mask branch。

Mask branch 由 FCN (Fully Convolutional Network) 的概念所構成, Mask branch 會在每個 RoI (Region of Interest) 上以 pixel-to-pixel 的方式預測出 segmentation mask。但原來 Faster R-CNN 的設計無法在 inputs 與 outputs 間做 pixel-to-pixel 的對齊 (pixel-to-pixel alignment)。為了要解決對齊的問題, Mask R-CNN 多設計了 RoIAlign 用來保存原本的空間位置。FCN 的架構可以參考 [Fully Convolutional Networks for Semantic Segmentation] 提出的示意圖,

<div class="card mb-3">
    <img class="card-img-top" src="{{ site.baseurl }}/assets/img/2017-07-31-mask-rcnn/pixel-to-pixel.png"/>
</div>

### Faster R-CNN 簡短回顧:

Faster R-CNN 在訓練時由兩個階段所組成。第一階段, 以 RPN (Region Proposal Network) 產生候選外框 (bounding box)。
第二階段, 用原有的 Fast R-CNN 利用 RoI pooling 從候選外框擷取出特徵並進行分類與 bounding box regression。

### Mask R-CNN:

Mask R-CNN 繼承原來 Fast R-CNN 的架構, 在第二階段時會對每一個 RoI 預測出類別與 box offset, 之後產出 binary mask。 Mask R-CNN 定義的 loss function: $$ L = L_{cls} + L_{box}  + L_{mask} $$ , 將 3 種 Loss 結合, $$L_{cls}$$ 與 $$L_{box}$$ 定義可以參考 Faster R-CNN 原文, 與新加入的 $$ L_{mask} $$。在 Mask branch 時預測出 $$ K $$ 個 $$ m \times m $$ 的 mask, 也就是對 $$ K $$ 種分類, 每種分類皆會會預測一種 mask。

在預測 binary mask 時, 會以 per-pixel sigmoid 對每個 pixel 預測, 而 $$ L_{mask} $$ 是對所有 binary cross-entropy loss 取平均。每個 RoI 都會有其對應的 ground-truth class $$ k $$, 而只有第 $$k$$ 個 mask 會貢獻於 $$ L_{mask} $$。 在 Fast R-CNN 的 Classification branch 對 RoI 進行預測類別, 並利用這個預測出的類別產出該類別的 mask, 這也是為什麼 $$ L_{mask} $$ 的定義能讓 network 對每個類別產出 mask 但又不會與其他類別的 mask 競爭。

### RoIAlign

ROIPool 是用來提取 feature maps 的方法。 在 Fast RCNN, 會對每一個 RoI 進行 RoI pooling, 得到固定大小 (e.g., 7 x 7 ) 的 feature map。關於 RoI pooling layer 的詳細介紹可以參考連結 ([Link]) 或下圖。

<div class="card mb-3">
    <img class="card-img-top" src="{{ site.baseurl }}/assets/img/2017-07-31-mask-rcnn/roi_pooling.gif"/>
    <div class="card-body bg-light">
        <div class="card-text"></div>
    </div>
</div>

在進行 RoI pooling 時會進行量化, 但在量化的過程中會造成 RoI 與擷取特徵 (extracted feature) 間產生 misalignment。為了解決這個問題, 本文提出了新的 RoIAlign Layer, 用來對 input 與擷取特徵做對齊。

<div class="card mb-3">
    <img class="card-img-top" src="{{ site.baseurl }}/assets/img/2017-07-31-mask-rcnn/roi_mapping.jpg"/>
    <div class="card-body bg-light">
        <div class="card-text"></div>
    </div>
</div>

如上圖, 假設一張 128x128 原圖與 25x25 的 feature map, 如果 RoI 是位於原圖左上角 15x15, 而要從 25x25 的 feature map 擷取此 RoI 特徵, 我們應該要擷取的 pixels 範圍大約為 2.93 x 2.93 pixels ($$ 15 \times \frac{25}{128} = 2.93 $$)。在原來的 RoI pooling 會捨去小數點擷取出 2 x 2 pixels, 也因為捨去所以會造成細微的 misalignment。不同的地方在於,
RoIAlign 利用雙線性內差 ([Bilinear interpolation]) 來得到位於 2.93 上大致的 pixel 數值。

<div class="card mb-3">
    <img class="card-img-top" src="{{ site.baseurl }}/assets/img/2017-07-31-mask-rcnn/instance_seg.png"/>
    <div class="card-body bg-light">
        <div class="card-text"></div>
    </div>
</div>

### Implementation Details

#### Training:

在訓練 Fast R-CNN 時, 每個 RoI 皆會被賦予標記, 如果 RoI 與 ground-truth box 的 IoU 大於 0.5, 就會賦予 positive 的標記, 反之如果小於 0.5 就會賦予 negative。 Mask loss ($$L_{mask}$$) 只會針對 positive 的 RoI 做計算, 預測的目標是希望 RoI 與對應的 ground-truth mask 交集能夠越多越好。

#### Inference:

再進行推論測試時, 會產出多個 proposal 並對每個 proposal 預測出 score 與 bounding box region, 再利用 NMS 以 score 與 bounding box region 作為依據, 將重疊的 proposal 結合。 Mask branch 會對分數前 100 高的 proposal 預測出該 proposal 該類別的 mask (所屬類別已經在 classification branch 時得到)。最後會將 $$ m \times m $$ 的 mask, resize 到原有 RoI 的大小, resize 後的 mask > 0.5 的數值做 threshold 就可以得到預測的 binary mask。 讀者可以參考 Mask R-CNN 在 COCO datasets 下的預測結果,

<div class="card mb-3">
    <img class="card-img-top" src="{{ site.baseurl }}/assets/img/2017-07-31-mask-rcnn/coco_result.png"/>
    <div class="card-body bg-light">
        <div class="card-text"></div>
    </div>
</div>

### Conclusion:

Mask R-CNN 延伸了 Faster R-CNN 的架構, 在原有架構新加了 Mask branch 用來預測物件的 mask。Mask R-CNN 在 training 的時候可以以 end-to-end 的方式訓練出 object detector 與 mask detector。在本文中 Mask R-CNN 結合了 Feature Pyramid Network 擷取各個 layer 的 RoI 特徵, 讀者可以參考下圖與 [FPN] 的詳細作法,

<div class="card mb-3">
    <img class="card-img-top" src="{{ site.baseurl }}/assets/img/2017-07-31-mask-rcnn/framework.png"/>
    <div class="card-body bg-light">
        <div class="card-text"></div>
    </div>
</div>

跟 Faster R-CNN 不同的是原來 Faster R-CNN 會將原圖 resize 到短邊 600, Mask R-CNN 則是 resize 到 800, anchor boxes 的 scale 與 ratio 組合也由 12 種提升到 15 種, 讀者有興趣可以參考本文詳細的實驗結果。 目前 Mask R-CNN 的 code 也已經 implement 在不同種 DL library 上, 有興趣的讀者可以參考以下連結。

[原文](https://arxiv.org/pdf/1703.06870.pdf)  
[Implementation in Pytorch](https://github.com/felixgwu/mask_rcnn_pytorch)  
[Implementation in Tensorflow](https://github.com/CharlesShang/FastMaskRCNN)  
[Implementation in Caffe](https://github.com/jasjeetIM/Mask-RCNN)  
[Reference 1](https://blog.athelas.com/a-brief-history-of-cnns-in-image-segmentation-from-r-cnn-to-mask-r-cnn-34ea83205de4)  
[Reference 2](https://deepsense.io/region-of-interest-pooling-explained/)

[fully convolutional networks for semantic segmentation]: https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf
[fpn]: https://arxiv.org/pdf/1612.03144.pdf
[bilinear interpolation]: https://en.wikipedia.org/wiki/Bilinear_interpolation
